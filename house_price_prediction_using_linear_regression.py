# -*- coding: utf-8 -*-
"""House Price Prediction Using Linear Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CEP0NC0n5Xo80Php2WN-hxF_5z5ZegBB

# Prodigy InfoTech Machine Learning Internship

Name:- Sampurna dey

Task 1:- House Price Prediction Using Linear Regression

Summary to Explain Project


*   Display top 5 rows of the dataset
*   Get information about the set

*   Model Sele tion & Prediction
*   Save the model
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option('display.max_rows',None)

import joblib

from google.colab import files


uploaded = files.upload()

from google.colab import files


uploaded = files.upload()

df_Test = pd.read_csv('test.csv')
df_Train = pd.read_csv('train.csv')

df_Train.head()

df_Train.describe()

df_Test.describe()

df_Train.info()

print("shape")
print("Training data:",df_Train.shape)
print("Test data:",df_Test.shape)

"""Get Different dtype column"""

s = (df_Train.dtypes == 'object')
object_cols = list(s[s].index)
print("categorical variables:")
print(object_cols)

s = (df_Train.dtypes == 'int')
num_cols = list(s[s].index)
print("Integer variables:")
print(num_cols)

s = (df_Train.dtypes == 'float')
num_cols = list(s[s].index)
print("real variables:")
print(num_cols)

"""Check & handle missing values"""

df = [df_Train,df_Test]
df_combined = pd.concat(df).reset_index(drop=True)

df_combined.head()

print(df_combined.isnull().sum())

plt.figure(figsize=(18,6))
plt.title('Heatmap of missing values')
sns.heatmap(df_combined.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""Handling Categorical Columns"""

unique_values =[]
for col in object_cols:
  unique_values.append(df_combined[col].unique().size)
plt.figure(figsize=(18,6))
plt.title('No. unique values of Categorical features')
plt.xticks(rotation=90)
sns.barplot(x=object_cols,y=unique_values)

plt.figure(figsize=(18,36))
plt.title('Categorical Features:Distribution')
plt.xticks(rotation=90)
index=1
for col in object_cols:
  y = df_combined[col].value_counts()
  plt.subplot(11,4,index)
  plt.xticks(rotation=90)
  sns.barplot(x=list(y.index),y=y)
  index +=1

"""Drop unnecessary column and convert dtype of column"""

df_combined.drop(columns='Id',inplace=True);print('Drop Id\n')
df_combined['MSZoning']=df_combined['MSZoning'].fillna(df_combined['MSZoning'].mode()[0])
df_combined['LotFrontage']=df_combined['LotFrontage'].fillna(df_combined['LotFrontage'].mean())
df_combined.drop(columns ='Alley',inplace=True);print('Drop Alley\n')

print(df_combined['Utilities'].value_counts())

df_combined.drop(columns='Utilities',inplace=True);print('Drop Utilities\n')

df_combined['Exterior1st']=df_combined['Exterior1st'].fillna(df_combined['Exterior1st'].mode()[0])
df_combined['Exterior2nd']=df_combined['Exterior2nd'].fillna(df_combined['Exterior2nd'].mode()[0])
df_combined['MasVnrType']=df_combined['MasVnrType'].fillna(df_combined['MasVnrType'].mode()[0])
df_combined['MasVnrArea']=df_combined['MasVnrArea'].fillna(df_combined['MasVnrArea'].mode()[0])
df_combined['Electrical']=df_combined['Electrical'].fillna(df_combined['Electrical'].mode()[0])
df_combined['KitchenQual']=df_combined['KitchenQual'].fillna(df_combined['KitchenQual'].mode()[0])
df_combined['Functional']=df_combined['Functional'].fillna(df_combined['Functional'].mode()[0])

df_combined['FireplaceQu'] = df_combined['FireplaceQu'].fillna('NA');
print('FireplaceQu: Fill NA values for missing values\n')
df_combined.loc[(df_combined['PoolQC'].isnull())& df_combined['PoolArea']>0][['PoolQC','PoolArea']]
df_combined.at[2599,'PoolQC']=df_combined['PoolQC'].mode()[0];
print('PoolQC: Use Made for missing value with non-zero Poolarea\n')
df_combined['PoolQC']=df_combined['PoolQC'].fillna('NA');
print('PoolQC: Use NA for remaining missing values\n')

df_combined['SaleType'].fillna(df_combined['SaleType'].mode()[0],inplace=True)
df_combined.drop(columns=['Fence','MiscFeature','SalePrice'],inplace=True);

print('Fill missing values of Basement features with NA or 0\n')
df_combined['BsmtQual']= df_combined['BsmtQual'].fillna('NA')
df_combined['BsmtCond']= df_combined['BsmtCond'].fillna('NA')
df_combined['BsmtExposure']= df_combined['BsmtExposure'].fillna('NA')
df_combined['BsmtFinType1']= df_combined['BsmtFinType1'].fillna('NA')
df_combined['BsmtFinType2']= df_combined['BsmtFinType2'].fillna('NA')

df_combined['BsmtFinSF1']= df_combined['BsmtFinSF1'].fillna(int(0))
df_combined['BsmtFinSF2']= df_combined['BsmtFinSF2'].fillna(int(0))
df_combined['BsmtUnfSF']= df_combined['BsmtUnfSF'].fillna(int(0))
df_combined['TotalBsmtSF']= df_combined['TotalBsmtSF'].fillna(int(0))
df_combined['BsmtFullBath']= df_combined['BsmtFullBath'].fillna(int(0))
df_combined['BsmtHalfBath']= df_combined['BsmtHalfBath'].fillna(int(0))

print('Fill missing values of Garage features with NA or 0\n')
df_combined['GarageType']= df_combined['GarageType'].fillna('NA')
df_combined['GarageFinish']= df_combined['GarageFinish'].fillna('NA')
df_combined['GarageCond']= df_combined['GarageCond'].fillna('NA')
df_combined['GarageQual']= df_combined['GarageQual'].fillna('NA')
df_combined['GarageCars']= df_combined['GarageCars'].fillna(int(0))
df_combined['GarageArea']= df_combined['GarageArea'].fillna(int(0))
df_combined['GarageYrBlt']= df_combined['GarageYrBlt'].fillna(int(0))

df_combined.head()

print(df_combined.isnull().sum().sum())

"""Data Preprocessing"""

from sklearn.preprocessing import OneHotEncoder

s = (df_combined.dtypes=='object')
object_cols=list(s[s].index)
print("Categorical Variables:")
print(object_cols)
print('No. of . categorical features:',len(object_cols))

"""Applying One-Hot Encoding"""

OH_encoder = OneHotEncoder(sparse=False)
OH_cols= pd.DataFrame(OH_encoder.fit_transform(df_combined[object_cols]))
OH_cols.index = df_combined.index
OH_cols.columns = OH_encoder.get_feature_names_out(input_features=object_cols)
df_final = df_combined.drop(object_cols,axis=1)
df_final = pd.concat([df_final,OH_cols],axis=1)

df_final.head()

"""Splited Dataset informations"""

# Check that the shapes are consistent

print('df_final shape:',df_final.shape)
print('df_train shape:',df_Train.shape)
print('df_test shape:',df_Test.shape)
X_Train = pd.DataFrame(df_final[:1460])
X_Test = pd.DataFrame(df_final[1460:])
Y_Train = df_Train['SalePrice']

print('\nCheck that the datasets are consistent:\n')
print('X_train shape:',X_Train.shape)
print('Y_train shape:',Y_Train.shape)
print('X_test shape:',X_Test.shape)

"""Model Selection & Prediction"""

from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
X_Train , X_valid, Y_Train, Y_valid = train_test_split(X_Train,Y_Train, train_size=0.8, test_size=0.2,random_state=0)

from sklearn.ensemble import RandomForestRegressor

model_RFR = RandomForestRegressor()
model_RFR.fit(X_Train,Y_Train)
Y_pred = model_RFR.predict(X_valid)
print(mean_absolute_error(Y_valid,Y_pred))

from sklearn.ensemble import GradientBoostingRegressor

model_GBR = GradientBoostingRegressor()
model_GBR.fit(X_Train,Y_Train)
Y_pred = model_GBR.predict(X_valid)
print(mean_absolute_error(Y_valid,Y_pred))

from sklearn.linear_model import SGDRegressor

model_SGD = SGDRegressor()
model_SGD.fit(X_Train,Y_Train)
Y_pred = model_SGD.predict(X_valid)
print(mean_absolute_error(Y_valid,Y_pred))

import warnings
warnings.filterwarnings('ignore')

from xgboost import XGBRegressor

model_XGBR = XGBRegressor(learning_rate=0.03,n_estimators=200,objective='reg:squarederror')
model_XGBR.fit(X_Train,Y_Train)
Y_pred = model_XGBR.predict(X_valid)
print(mean_absolute_error(Y_valid,Y_pred))

plt.figure()
plt.title('Comparison of Sale Price of Predicted and Actual Values')
plt.scatter(Y_Train,model_RFR.predict(X_Train),label='Random Forest')
plt.scatter(Y_Train,model_XGBR.predict(X_Train),label='XGBR')
plt.legend()

from sklearn.model_selection import GridSearchCV
model = XGBRegressor()

n_estimators = [100,200,500]
learning_rates = [0.03,0.1,0.3]
objectives = ['reg:squarederror']

#Define the grid of hyperpameters to search
hyperparameter_grid ={
    'n_estimators': n_estimators,
    'learning_rate': learning_rates,
    'objective' : objectives
    }
grid_cv = GridSearchCV(estimator = model,
                       param_grid = hyperparameter_grid,
                       scoring = 'neg_mean_absolute_error',
                       return_train_score= True)
grid_cv.fit(X_Train,Y_Train)

print(grid_cv.best_score_)
#print(model_SGD.best_score_)

grid_cv.best_estimator_
#model_SGD.best_estimator_

regressor=grid_cv.best_estimator_
#regressor = model_SGD
Y_pred = regressor.predict(X_valid)
print(mean_absolute_error(Y_valid,Y_pred))

plt.figure()
plt.title('Comparison of Sale Price of Predicted and Actual values')
plt.scatter(Y_Train,model_RFR.predict(X_Train),label='Random Forest')
plt.scatter(Y_Train,model_XGBR.predict(X_Train),label='XGBR')
plt.scatter(Y_Train,regressor.predict(X_Train),label='Best Model')
plt.legend()

"""Submitting Data"""

Y_pred = regressor.predict(X_Test)

Y_pred

Y_pred.shape

sub = pd.DataFrame()
sub['Id'] = df_Test['Id']
sub['SalePrice'] = Y_pred

sub.head()

sub.tail()

sub.to_csv('Submission.csv')

"""Save the Model"""

joblib.dump(grid_cv,'house_price_predict')

model = joblib.load('house_price_predict')

model.predict(X_Test)